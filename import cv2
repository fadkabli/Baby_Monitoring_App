import cv2
import time

# Set parameters for face detection
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
min_face_size = 100
max_face_size = 500
max_face_covered_time = 5 # in seconds

# Define a function to detect faces in an image
def detect_faces(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(min_face_size, min_face_size), maxSize=(max_face_size, max_face_size))
    if len(faces) > 0:
        return True, faces
    else:
        return False, None

# Define a function to draw a rectangle around each face
def draw_face_rectangles(frame, faces):
    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

# Define a function to apply brightness and contrast to an image
def apply_brightness_contrast(frame, brightness=0, contrast=0):
    if brightness != 0:
        if brightness > 0:
            shadow = brightness
            highlight = 255
        else:
            shadow = 0
            highlight = 255 + brightness
        alpha_b = (highlight - shadow)/255
        gamma_b = shadow
        frame = cv2.addWeighted(frame, alpha_b, frame, 0, gamma_b)

    if contrast != 0:
        f = 131*(contrast + 127)/(127*(131-contrast))
        alpha_c = f
        gamma_c = 127*(1-f)
        frame = cv2.addWeighted(frame, alpha_c, frame, 0, gamma_c)

    return frame

# Define a function to generate a video stream of face detection frames
def generate():
    video_capture = cv2.VideoCapture(0)
    start_time = None
    while True:
        success, frame = video_capture.read()
        if not success:
            break

        # Apply brightness and contrast to the frame
        frame = apply_brightness_contrast(frame, brightness=50, contrast=50)

        # Detect faces in the frame
        face_covered, faces = detect_faces(frame)

        # Draw rectangles around the faces
        if faces is not None:
            draw_face_rectangles(frame, faces)

        # Display warning message if face is covered for too long
        if face_covered:
            if start_time is None:
                start_time = time.time()
            elif time.time() - start_time > max_face_covered_time:
                cv2.putText(frame, "Warning: Face Covered for Too Long!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        else:
            start_time = None

        # Generate the video stream
        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

    # Release the video capture and destroy any open windows
    video_capture.release()
    cv2.destroyAllWindows()


# Define the Flask app
from flask import Flask, render_template, Response

app = Flask(__name__)

# Define the home page route
@app.route('/')
def index():
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    """Stream a video feed of face detection frames."""
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == '__main__':
    app.run(debug=True)

    
import cv2
import numpy as np
from flask import Flask, render_template, Response, request

app = Flask(__name__)

brightness = 50
contrast = 50
video_capture = None

def apply_brightness_contrast(frame):
    global brightness, contrast
    # adjust brightness and contrast
    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    l = np.float32(l)
    l = np.clip((contrast/50.0) * (l - 128) + 128 + brightness, 0, 255)
    l = np.uint8(l)
    lab = cv2.merge((l,a,b))
    # convert back to bgr
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

def detect_faces(frame):
    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    if len(faces) > 0:
        return True
    else:
        return False

def generate():
    """Generate a video stream of face detection frames."""
    global video_capture
    video_capture = cv2.VideoCapture(0)
    while True:
        success, frame = video_capture.read()
        if not success:
            break
        else:
            frame = apply_brightness_contrast(frame)
            face_covered = not detect_faces(frame)
            if face_covered:
                cv2.putText(frame, "Face Covered", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            else:
                cv2.putText(frame, "Face Not Covered", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

    # Release the video capture and destroy any open windows
    video_capture.release()
    cv2.destroyAllWindows()


@app.route('/')
def index():
    """Render the home page."""
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    """Stream a video feed of face detection frames."""
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/brightness', methods=['POST'])
def set_brightness():
    global brightness
    brightness = int(request.form['brightness'])
    return ('', 204)


@app.route('/contrast', methods=['POST'])
def set_contrast():
    global contrast
    contrast = int(request.form['contrast'])
    return ('', 204)


@app.route('/start', methods=['POST'])
def start():
    global video_capture
    if video_capture is None:
        video_capture = cv2.VideoCapture(0)
    return ('', 204)


@app.route('/stop', methods=['POST'])
def stop():
    global video_capture
    if video_capture is not None:
        video_capture.release()
        cv2.destroyAllWindows()
        video_capture = None
    return ('', 204)


if __name__ == '__main__':
    app.run(debug=True)


from flask import Flask, render_template, Response
import cv2
import numpy as np

app = Flask(__name__)

# Load the Haar Cascade classifier for face detection
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# Load the face mask detector model
mask_net = cv2.dnn.readNet('res10_300x300_ssd_iter_140000_fp16.caffemodel', 'deploy.prototxt')

# Open the default camera
video_capture = cv2.VideoCapture(0)

def detect_faces(frame):
    """Detect faces in a video frame using the Haar Cascade classifier."""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)
    for (x, y, w, h) in faces:
        # Extract the face region from the frame
        face = frame[y:y+h, x:x+w]
        # Preprocess the face image for facemask detection
        blob = cv2.dnn.blobFromImage(face, 1.0, (300, 300), (104.0, 177.0, 123.0))
        # Pass the face image through the facemask detection model
        mask_net.setInput(blob)
        detections = mask_net.forward()
        # Get the confidence score for facemask detection
        confidence = detections[0, 0, 0, 2]
        # Draw the facemask detection result on the frame
        if confidence > 0.8:
            label = "Mask Detected"
            color = (0, 255, 0)
            face_covered = False
        else:
            label = "Mask Not Detected"
            color = (0, 0, 255)
            face_covered = True
        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
    return frame, face_covered

def apply_brightness_contrast(input_img, brightness = 30, contrast = 22):
    """Apply brightness and contrast adjustments to an input image."""
    if brightness != 0:
        if brightness > 0:
            shadow = brightness
            highlight = 255
        else:
            shadow = 0
            highlight = 255 + brightness
        alpha_b = (highlight - shadow)/255
        gamma_b = shadow

        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)
    else:
        buf = input_img.copy()

    if contrast != 0:
        f = 131*(contrast + 127)/(127*(131-contrast))
        alpha_c = f
        gamma_c = 127*(1-f)

        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)

    return buf

def gen_frames():
    """Generate a video stream of face detection frames."""
    while True:
        success, frame = video_capture.read()
        if not success:
            break
        else:
            frame, face_covered = detect_faces(frame)
            frame = apply_brightness_contrast(frame)
            ret, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')


@app.route('/')
def index():
    """Render the index page with the video stream."""
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    """Stream video frames to the webpage."""
    return Response(gen_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == '__main__':
    app.run(debug=True)


